# Documentation

## Overview

This documentation provides detailed information on our evaluation framework, including the datasets, evaluation metrics, and methodologies used.

## Datasets

- **BoolQ:** A dataset for yes/no questions based on short passages.
- **CSWA:** A dataset for sentiment analysis.
- **IWSLT:** A dataset for machine translation tasks.
- **SamSum:** A dataset for abstractive dialogue summarization.

## Evaluation Metrics

We use two main frameworks for evaluation:
1. **Manual Framework:** Involves human annotators evaluating the outputs.
2. **Adaptive Framework:** Uses adaptive algorithms to evaluate the outputs.

## Methodologies

